{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST('./mnist', train=True,transform=torchvision.transforms.ToTensor(), download=True)\n",
    "train_loader = Data.DataLoader(dataset=train_set, batch_size=4, shuffle=True)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST('./mnist', train=False, transform=torchvision.transforms.ToTensor())\n",
    "test_loader = Data.DataLoader(dataset=test_set, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(LeNet, self).__init__()\n",
    "    self.conv1 = nn.Sequential(nn.Conv2d(1, 6, 3, 1, 2), nn.ReLU(),\n",
    "                  nn.MaxPool2d(2, 2))\n",
    " \n",
    "    self.conv2 = nn.Sequential(nn.Conv2d(6, 16, 5), nn.ReLU(),\n",
    "                  nn.MaxPool2d(2, 2))\n",
    " \n",
    "    self.fc1 = nn.Sequential(nn.Linear(16 * 5 * 5, 120),\n",
    "                 nn.BatchNorm1d(120), nn.ReLU())\n",
    " \n",
    "    self.fc2 = nn.Sequential(\n",
    "      nn.Linear(120, 84),\n",
    "      nn.BatchNorm1d(84),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(84, 10))\n",
    "        # 最后的结果一定要变为 10，因为数字的选项是 0 ~ 9\n",
    " \n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = x.view(x.size()[0], -1)\n",
    "    x = self.fc1(x)\n",
    "    x = self.fc2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,100] loss:1.799\n",
      "[1,200] loss:1.303\n",
      "[1,300] loss:1.093\n",
      "[1,400] loss:0.941\n",
      "[1,500] loss:0.843\n",
      "[1,600] loss:0.730\n",
      "[1,700] loss:0.649\n",
      "[1,800] loss:0.601\n",
      "[1,900] loss:0.695\n",
      "[1,1000] loss:0.622\n",
      "[1,1100] loss:0.637\n",
      "[1,1200] loss:0.652\n",
      "[1,1300] loss:0.614\n",
      "[1,1400] loss:0.602\n",
      "[1,1500] loss:0.568\n",
      "[1,1600] loss:0.470\n",
      "[1,1700] loss:0.538\n",
      "[1,1800] loss:0.492\n",
      "[1,1900] loss:0.504\n",
      "[1,2000] loss:0.525\n",
      "[1,2100] loss:0.511\n",
      "[1,2200] loss:0.393\n",
      "[1,2300] loss:0.525\n",
      "[1,2400] loss:0.468\n",
      "[1,2500] loss:0.487\n",
      "[1,2600] loss:0.546\n",
      "[1,2700] loss:0.452\n",
      "[1,2800] loss:0.438\n",
      "[1,2900] loss:0.406\n",
      "[1,3000] loss:0.414\n",
      "[1,3100] loss:0.387\n",
      "[1,3200] loss:0.444\n",
      "[1,3300] loss:0.410\n",
      "[1,3400] loss:0.438\n",
      "[1,3500] loss:0.380\n",
      "[1,3600] loss:0.420\n",
      "[1,3700] loss:0.342\n",
      "[1,3800] loss:0.363\n",
      "[1,3900] loss:0.483\n",
      "[1,4000] loss:0.418\n",
      "[1,4100] loss:0.309\n",
      "[1,4200] loss:0.426\n",
      "[1,4300] loss:0.361\n",
      "[1,4400] loss:0.470\n",
      "[1,4500] loss:0.354\n",
      "[1,4600] loss:0.357\n",
      "[1,4700] loss:0.387\n",
      "[1,4800] loss:0.381\n",
      "[1,4900] loss:0.373\n",
      "[1,5000] loss:0.338\n",
      "[1,5100] loss:0.287\n",
      "[1,5200] loss:0.265\n",
      "[1,5300] loss:0.451\n",
      "[1,5400] loss:0.400\n",
      "[1,5500] loss:0.338\n",
      "[1,5600] loss:0.336\n",
      "[1,5700] loss:0.432\n",
      "[1,5800] loss:0.305\n",
      "[1,5900] loss:0.381\n",
      "[1,6000] loss:0.321\n",
      "[1,6100] loss:0.400\n",
      "[1,6200] loss:0.404\n",
      "[1,6300] loss:0.324\n",
      "[1,6400] loss:0.316\n",
      "[1,6500] loss:0.345\n",
      "[1,6600] loss:0.345\n",
      "[1,6700] loss:0.438\n",
      "[1,6800] loss:0.290\n",
      "[1,6900] loss:0.302\n",
      "[1,7000] loss:0.311\n",
      "[1,7100] loss:0.384\n",
      "[1,7200] loss:0.229\n",
      "[1,7300] loss:0.261\n",
      "[1,7400] loss:0.384\n",
      "[1,7500] loss:0.440\n",
      "[1,7600] loss:0.382\n",
      "[1,7700] loss:0.328\n",
      "[1,7800] loss:0.404\n",
      "[1,7900] loss:0.409\n",
      "[1,8000] loss:0.420\n",
      "[1,8100] loss:0.222\n",
      "[1,8200] loss:0.357\n",
      "[1,8300] loss:0.277\n",
      "[1,8400] loss:0.301\n",
      "[1,8500] loss:0.300\n",
      "[1,8600] loss:0.287\n",
      "[1,8700] loss:0.401\n",
      "[1,8800] loss:0.224\n",
      "[1,8900] loss:0.276\n",
      "[1,9000] loss:0.356\n",
      "[1,9100] loss:0.313\n",
      "[1,9200] loss:0.364\n",
      "[1,9300] loss:0.306\n",
      "[1,9400] loss:0.221\n",
      "[1,9500] loss:0.276\n",
      "[1,9600] loss:0.334\n",
      "[1,9700] loss:0.306\n",
      "[1,9800] loss:0.304\n",
      "[1,9900] loss:0.356\n",
      "[1,10000] loss:0.276\n",
      "[1,10100] loss:0.282\n",
      "[1,10200] loss:0.299\n",
      "[1,10300] loss:0.240\n",
      "[1,10400] loss:0.277\n",
      "[1,10500] loss:0.255\n",
      "[1,10600] loss:0.366\n",
      "[1,10700] loss:0.286\n",
      "[1,10800] loss:0.336\n",
      "[1,10900] loss:0.325\n",
      "[1,11000] loss:0.244\n",
      "[1,11100] loss:0.283\n",
      "[1,11200] loss:0.263\n",
      "[1,11300] loss:0.277\n",
      "[1,11400] loss:0.296\n",
      "[1,11500] loss:0.213\n",
      "[1,11600] loss:0.291\n",
      "[1,11700] loss:0.237\n",
      "[1,11800] loss:0.373\n",
      "[1,11900] loss:0.292\n",
      "[1,12000] loss:0.247\n",
      "[1,12100] loss:0.276\n",
      "[1,12200] loss:0.239\n",
      "[1,12300] loss:0.374\n",
      "[1,12400] loss:0.358\n",
      "[1,12500] loss:0.341\n",
      "[1,12600] loss:0.310\n",
      "[1,12700] loss:0.329\n",
      "[1,12800] loss:0.400\n",
      "[1,12900] loss:0.260\n",
      "[1,13000] loss:0.261\n",
      "[1,13100] loss:0.263\n",
      "[1,13200] loss:0.208\n",
      "[1,13300] loss:0.296\n",
      "[1,13400] loss:0.301\n",
      "[1,13500] loss:0.231\n",
      "[1,13600] loss:0.324\n",
      "[1,13700] loss:0.248\n",
      "[1,13800] loss:0.320\n",
      "[1,13900] loss:0.253\n",
      "[1,14000] loss:0.389\n",
      "[1,14100] loss:0.278\n",
      "[1,14200] loss:0.266\n",
      "[1,14300] loss:0.182\n",
      "[1,14400] loss:0.225\n",
      "[1,14500] loss:0.222\n",
      "[1,14600] loss:0.275\n",
      "[1,14700] loss:0.186\n",
      "[1,14800] loss:0.291\n",
      "[1,14900] loss:0.331\n",
      "[1,15000] loss:0.313\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "batch_size = 64\n",
    "LR = 0.001\n",
    " \n",
    "net = LeNet().to(device)\n",
    "# 损失函数使用交叉熵\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 优化函数使用 Adam 自适应优化算法\n",
    "optimizer = optim.Adam(\n",
    "  net.parameters(),\n",
    "  lr=LR,\n",
    ")\n",
    " \n",
    "epoch = 1\n",
    "if __name__ == '__main__':\n",
    "  for epoch in range(epoch):\n",
    "    sum_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "      inputs, labels = data\n",
    "      inputs, labels = Variable(inputs), Variable(labels)\n",
    "      optimizer.zero_grad() #将梯度归零\n",
    "      outputs = net(inputs) #将数据传入网络进行前向运算\n",
    "      loss = criterion(outputs, labels) #得到损失函数\n",
    "      loss.backward() #反向传播\n",
    "      optimizer.step() #通过梯度做一步参数更新\n",
    " \n",
    "      sum_loss += loss.item()\n",
    "      if i % 100 == 99:\n",
    "        print('[%d,%d] loss:%.03f' %\n",
    "           (epoch + 1, i + 1, sum_loss / 100))\n",
    "        sum_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct1:  tensor(9680)\n",
      "Test acc: 0.968\n"
     ]
    }
   ],
   "source": [
    "net.eval() #将模型变换为测试模式\n",
    "correct = 0\n",
    "total = 0\n",
    "for data_test in test_loader:\n",
    "    images, labels = data_test\n",
    "    images, labels = Variable(images), Variable(labels)\n",
    "    output_test = net(images)\n",
    "    _, predicted = torch.max(output_test, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "print(\"correct1: \", correct)\n",
    "print(\"Test acc: {0}\".format(correct.item() /len(test_set)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
